{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ac9241-c7d6-48af-8623-fff0436f6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493df52a-c417-4fcf-9882-ff1a007b766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cache_dir = \"/root/autodl-fs\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = cache_dir"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e6dd1bf-3f7f-47a2-9222-c4ab7723146f",
   "metadata": {},
   "source": [
    "Load BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb24e5a-fbf9-4c88-83cd-03d8baf9c0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)# OPTIONAL\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "model.to('cuda')  # if you have gpu\n",
    "\n",
    "\n",
    "def predict_masked_sent(text, top_k=5):\n",
    "    # Tokenize input\n",
    "    text = \"[CLS] %s [SEP]\"%text\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    masked_index = tokenized_text.index(\"[MASK]\")\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    tokens_tensor = tokens_tensor.to('cuda')    # if you have gpu\n",
    "    predicted_token = \"\"\n",
    "\n",
    "    # Predict all tokens\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "    probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "    top_k_weights, top_k_indices = torch.topk(probs, top_k, sorted=True)\n",
    "\n",
    "    for i, pred_idx in enumerate(top_k_indices):\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "        token_weight = top_k_weights[i]\n",
    "        print(\"[MASK]: '%s'\"%predicted_token, \" | weights:\", float(token_weight))\n",
    "    return predicted_token"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a40ac975-f5d6-48a2-b2d4-3ee2587eb04d",
   "metadata": {},
   "source": [
    "Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4991c1-fd72-4773-94a6-59c55c8c3920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MASK]: 'maybe'  | weights: 0.2179914116859436\n",
      "[MASK]: 'looking'  | weights: 0.18057651817798615\n",
      "[MASK]: 'look'  | weights: 0.05956616625189781\n",
      "[MASK]: 'hope'  | weights: 0.041712548583745956\n",
      "[MASK]: 'try'  | weights: 0.031869422644376755\n",
      "[MASK]: 'else'  | weights: 0.15114066004753113\n",
      "[MASK]: 'different'  | weights: 0.10842850804328918\n",
      "[MASK]: 'better'  | weights: 0.09416163712739944\n",
      "[MASK]: 'more'  | weights: 0.04375604912638664\n",
      "[MASK]: 'new'  | weights: 0.03972452133893967\n",
      "[MASK]: 'on'  | weights: 0.949520468711853\n",
      "[MASK]: 'in'  | weights: 0.02288668230175972\n",
      "[MASK]: 'around'  | weights: 0.00320236012339592\n",
      "[MASK]: ','  | weights: 0.002488137222826481\n",
      "[MASK]: 'there'  | weights: 0.002456692047417164\n",
      "[MASK]: 'me'  | weights: 0.670590341091156\n",
      "[MASK]: 'him'  | weights: 0.09520667791366577\n",
      "[MASK]: 'her'  | weights: 0.07619468867778778\n",
      "[MASK]: 'us'  | weights: 0.02384626865386963\n",
      "[MASK]: 'them'  | weights: 0.009263100102543831\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory containing the files\n",
    "directory = 'raw_data'\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        # Open the input file\n",
    "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as infile, open(os.path.join('cleared_data', filename), 'w', encoding='utf-8') as outfile:\n",
    "            for line in infile:\n",
    "                max_length = 512  \n",
    "\n",
    "                if len(line) > max_length:\n",
    "                    line = line[:max_length]\n",
    "                modified_line = line\n",
    "                if \"[inaudible]\" in line or \"[redacted]\" in line or \"[crosstalk]\" in line:\n",
    "                    # Replace and tag occurrences of \"[inaudible]\", \"[redacted]\", and \"[crosstalk]\" with \"[MASK]\"\n",
    "                    modified_line = line.replace(\"[inaudible]\", \"[MASK]\").replace(\"[redacted]\", \"[MASK]\").replace(\"[crosstalk]\", \"[MASK]\")\n",
    "                    \n",
    "                    mask_count = modified_line.count(\"[MASK]\")\n",
    "                    \n",
    "                    # Replace each occurrence of [MASK] with the predicted word\n",
    "                    for _ in range(mask_count):\n",
    "                        max_length = 512 \n",
    "                        \n",
    "                        if len(modified_line) > max_length:\n",
    "                            modified_line1 = modified_line[:max_length]\n",
    "                            modified_line2 = modified_line[max_length]\n",
    "                            replaced = predict_masked_sent(modified_line1, top_k=1)\n",
    "                            modified_line1 = modified_line1.replace(\"[MASK]\", replaced, 1)\n",
    "                            \n",
    "                            replaced = predict_masked_sent(modified_line2, top_k=1)\n",
    "                            modified_line2 = modified_line2.replace(\"[MASK]\", replaced, 1) \n",
    "                            modified_line = modified_line1 + modified_line2\n",
    "                            print(\"truncate\")\n",
    "                        else:\n",
    "                            replaced = predict_masked_sent(modified_line, top_k=1)\n",
    "                            modified_line = modified_line.replace(\"[MASK]\", replaced, 1)\n",
    "        \n",
    "        \n",
    "                term_count = modified_line.count(\"[\")\n",
    "                for _ in range(term_count):\n",
    "                    index_start = modified_line.find(\"[\")\n",
    "                    if index_start != -1:\n",
    "                        index_end = modified_line.find(\"]\", index_start)\n",
    "                        if index_end != -1:\n",
    "                            if modified_line[index_end-1] == \"?\":\n",
    "                                # Remove '[' and '?' before ']'\n",
    "                                modified_line = modified_line[:index_start]+modified_line[index_start+1: index_end-1]+modified_line[index_end+1:]\n",
    "                            else: modified_line = modified_line[:index_start]+modified_line[index_end+1:]\n",
    "                \n",
    "                # Write the modified line to the output file\n",
    "                outfile.write(modified_line)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8c4c1b-2d2f-46dc-a221-d1a4ce3ffc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
