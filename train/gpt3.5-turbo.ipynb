{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f604908d-2bda-4ee2-ba5f-e9814494d7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8844280-7281-4fb0-b11d-986c8b9e95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66c3da1-c47d-4ff6-949a-1c5cf2999c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb74417-58b2-454c-810f-b415ad142386",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"Your name is Tom and you are now communicating with a psychologist in a therapy session.\n",
    "Answer the following questions as Tom and respond in a casual tone. Each of your replies should be no longer than three sentences.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a6ba5-0b1b-406a-8d7e-5a9b9602db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1d8b2-6a1c-4434-a424-cc19074548ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = 'SFT_dataset/GPT/SFT_GPT_362_oneturn_train.jsonl'\n",
    "validation_file_name = 'SFT_dataset/GPT/SFT_GPT_362_oneturn_val.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25f740-880a-4f0c-bac4-4b16c974646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_file_name, \"rb\") as file:\n",
    "    traning_response = openai.File.create(file=file, purpose=\"fine-tune\")\n",
    "\n",
    "training_file_id = traning_response[\"id\"]\n",
    "\n",
    "\n",
    "with open(validation_file_name, \"rb\") as file:\n",
    "    validation_response = openai.File.create(file=file, purpose=\"fine-tune\")\n",
    "\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"training file id:\", training_file_id)\n",
    "print(\"validation file id:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6647ed-6a9f-44a5-9a6c-a4c634e2594d",
   "metadata": {},
   "source": [
    "training_file_name = 'SFT_dataset/GPT/SFT_GPT_362_oneturn_train.jsonl'\n",
    "validation_file_name = 'SFT_dataset/GPT/SFT_GPT_362_oneturn_val.jsonl'\n",
    "training file id: file-NxCZBl0clKMFBjHyUmqs7QzG\n",
    "validation file id: file-EJuJ2rTrl476MiXs58zmtCJf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9e5fa-16d2-46a7-a296-69ae7e888389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f51b4-4b49-4561-ad2a-c6f5655f7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_name = \"gpt-4-oneturn\"\n",
    "\n",
    "response = openai.FineTuningJob.create(\n",
    "    training_file = training_file_id,\n",
    "    validation_file = validation_file_id,\n",
    "    model = \"gpt-4\",\n",
    "    suffix = suffix_name,\n",
    "    hyperparameters={\n",
    "    \"n_epochs\":2\n",
    "  }\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2bfca-487d-4155-ad31-66a6cffeabd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ae435-1342-4a18-83f0-7acfe3ca5789",
   "metadata": {},
   "source": [
    "gpt-3.5-oneturn   \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0125:the-university-of-melbourne:gpt-3-5-oneturn:9PUQsR99\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47748021-cddc-4c97-96e8-829eab8a7fc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = openai.FineTuningJob.list_events(id=job_id, limit=1574)\n",
    "\n",
    "events = response[\"data\"]\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print (event[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431625be-28c2-4346-8305-e3f27c5a3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "response = openai.FineTuningJob.list_events(id=job_id, limit=1574)\n",
    "events = response[\"data\"]\n",
    "events.reverse()\n",
    "\n",
    "with open('events.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Step', 'Full Validation Loss'])\n",
    "\n",
    "    for event in events:\n",
    "        message = event[\"message\"]\n",
    "        if \"validation loss\" in message:\n",
    "            step = message.split(': ')[0].split(' ')[1]\n",
    "            loss = message.split('validation loss=')[1]\n",
    "            writer.writerow([step, loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b3808-5bf5-4de6-b8e8-673723dacd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_id = response[\"fine_tuned_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b2af5b-a4f6-43b8-a348-ab03fd96b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_id = 'ft:gpt-3.5-turbo-0125:the-university-of-melbourne:gpt-3-5-oneturn:9PUQsR99'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768402ff-b927-4f6f-b4f6-f03538123b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81156a-c90e-46b2-9573-5cb93f91413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read questions from question.txt file and extract them\n",
    "questions = []\n",
    "with open(\"question.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        # Extract questions after the question number\n",
    "        question = line.split(\".\", 1)[-1].strip()\n",
    "        questions.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa1a32-0e8e-4bf3-8f6f-6e4d24c7fa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for dialogue inference\n",
    "with open(\"gpt_finetuned.txt\", \"a\") as output_file:\n",
    "    for question in questions:\n",
    "        \n",
    "        test_messages=[]\n",
    "        test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "        user_message = question\n",
    "        test_messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "        #Response after fine-tuning\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model = fine_tuned_model_id, messages = test_messages, temperature = 1, max_tokens=500, frequency_penalty=1\n",
    "        )\n",
    "        assistant_response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "        \n",
    "        # Append each answer to gpt_finetuned.txt\n",
    "        output_file.write(assistant_response + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc0a09-450b-4308-8779-ccfa940e6a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages=[]\n",
    "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "user_message = \"How do you feel recently?\"\n",
    "test_messages.append({\"role\": \"user\", \"content\": user_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b01a4-d303-4ae9-85bd-febf90176b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05be7a4e-c074-4930-b663-e3515206dfb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (D:\\Download\\anaconda3\\lib\\site-packages\\openai\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HELLO_~1\\AppData\\Local\\Temp/ipykernel_14912/1259619118.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m response = client.embeddings.create(\n\u001b[0;32m      5\u001b[0m     \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Your text string goes here\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (D:\\Download\\anaconda3\\lib\\site-packages\\openai\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=\"Your text string goes here\",\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "print(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1187a2-6eb5-4afc-8d65-d77d49def56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response after fine-tuning\n",
    "response = openai.Completion.create(\n",
    "    model = \"text-embedding-ada-002\", messages = test_messages, temperature = 0.5, max_tokens=500, frequency_penalty=0.5\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d7447-df05-4bd8-a357-4a1984cc43aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response without fine-tuning\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\", messages = test_messages, temperature = 0, max_tokens=500\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35e45f-7284-42b6-b813-bda207387229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.1.6 requires openai<2.0.0,>=1.24.0, but you have openai 0.28.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: tqdm in d:\\download\\anaconda3\\lib\\site-packages (from openai==0.28) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in d:\\download\\anaconda3\\lib\\site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in d:\\download\\anaconda3\\lib\\site-packages (from openai==0.28) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\download\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\download\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\download\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\download\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\download\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\download\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\download\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\download\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\download\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\download\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: colorama in d:\\download\\anaconda3\\lib\\site-packages (from tqdm->openai==0.28) (0.4.4)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.30.1\n",
      "    Uninstalling openai-1.30.1:\n",
      "      Successfully uninstalled openai-1.30.1\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "# Loop for dialogue inference\n",
    "with open(\"gpt.txt\", \"a\") as output_file:\n",
    "    for question in questions:\n",
    "        \n",
    "        test_messages=[]\n",
    "        test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "        user_message = question\n",
    "        test_messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "        #Response without fine-tuning\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model = \"gpt-3.5-turbo\", messages = test_messages, temperature = 0, max_tokens=500\n",
    "        )\n",
    "        \n",
    "        assistant_response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "        \n",
    "        # Append each answer to gpt_finetuned.txt\n",
    "        output_file.write(assistant_response + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437d5ff-111d-4c28-94fb-8fbe5bf58588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
